{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import math\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage as ndimage\n",
    "import scipy.ndimage.filters as filters\n",
    "\n",
    "from skimage import measure\n",
    "from data import generate as generate_training_data\n",
    "from network import setup as setup_network\n",
    "\n",
    "def sample_box(img, x, y):\n",
    "        box = np.zeros((1,1,box_size,box_size))\n",
    "        margin = int(math.floor(box_size / 2))\n",
    "        box[0:,0:,:]=img[x-margin:x+margin+1, y-margin:y+margin+1]\n",
    "        return box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_size = 29\n",
    "num_epochs = 10\n",
    "learning_rate = 0.00004\n",
    "sample_radius = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate training data and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_samples, t_labels, t_img = generate_training_data(\"train\",\n",
    "                                                box_size = box_size,\n",
    "                                                sample_radius = sample_radius,\n",
    "                                                enable_plotting = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_samples, v_labels, v_img = generate_training_data(\"validation\",\n",
    "                                                box_size = box_size,\n",
    "                                                sample_radius = sample_radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = t_img.mean()\n",
    "sigma = t_img.std()\n",
    "\n",
    "def normalize(data):\n",
    "    return (data - mu)/sigma\n",
    "\n",
    "t_img = normalize(t_img)\n",
    "v_img = normalize(v_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_var = T.tensor4('inputs')\n",
    "target_var = T.ivector('targets')\n",
    "network = setup_network(input_var, box_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var).mean()\n",
    "train_acc = T.mean(T.eq(T.argmax(prediction, axis=1), target_var), dtype=theano.config.floatX)\n",
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate=learning_rate, momentum=0.9)\n",
    "train_fn = theano.function([input_var, target_var], [loss, train_acc], updates=updates, allow_input_downcast=True)\n",
    "\n",
    "# Validation\n",
    "val_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "val_loss = lasagne.objectives.categorical_crossentropy(val_prediction, target_var).mean()\n",
    "val_acc = T.mean(T.eq(T.argmax(val_prediction, axis=1), target_var), dtype=theano.config.floatX)\n",
    "val_fn = theano.function([input_var, target_var], [val_loss, val_acc], allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in xrange(num_epochs):\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    indices = np.arange(len(t_labels))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    for idx in range(0, len(t_labels)):\n",
    "        ind = indices[idx]\n",
    "        labels = np.zeros(1)\n",
    "        labels[0] = t_labels[ind]\n",
    "        err, acc = train_fn(sample_box(t_img, t_samples[ind][0], t_samples[ind][1]), labels)\n",
    "        train_err += err\n",
    "        train_acc += acc\n",
    "\n",
    "    for idx in range(0, len(v_labels)):\n",
    "        labels = np.zeros(1)\n",
    "        labels[0] = v_labels[idx]\n",
    "        err, acc = val_fn(sample_box(v_img, v_samples[idx][0], v_samples[idx][1]), labels)\n",
    "        val_err += err\n",
    "        val_acc += acc\n",
    "\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss:\\t{:.6f}\".format(train_err / len(t_labels)))\n",
    "    print(\"  Training accuracy:\\t{:.2f} %\".format(train_acc / len(t_labels) * 100))\n",
    "    print(\"  validation loss:\\t{:.6f}\".format(val_err / len(v_labels)))\n",
    "    print(\"  validation accuracy:\\t{:.2f} %\".format(val_acc / len(v_labels) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_fn = theano.function([input_var], val_prediction)\n",
    "output = np.zeros((v_img.shape[0], v_img.shape[1], 2))\n",
    "\n",
    "margin = int(math.floor(box_size / 2))\n",
    "for x in xrange(margin, int(v_img.shape[0] - margin)):\n",
    "    for y in xrange(margin, int(v_img.shape[1]-margin)):\n",
    "        patch = v_img[x-margin:x+margin+1, y-margin:y+margin+1]\n",
    "        patch = patch.reshape(1,1, box_size, box_size)\n",
    "        output[x,y,:] = eval_fn(patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect local maxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = filters.gaussian_filter(output[:,:,1], 1) \n",
    "seg = heatmap>0.5\n",
    "detections = np.where(np.multiply(seg, heatmap == filters.maximum_filter(heatmap, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(v_img, interpolation='nearest', cmap=plt.cm.gray)\n",
    "plt.plot(detections[1], detections[0], 'b.', markersize=12, mew=3)\n",
    "        \n",
    "ax.axis('image')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.show()\n",
    "plt.rcParams['figure.figsize'] = 20,20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}